# EntryPromoteThread의 주기성 보장

EntryPromoteThread는 일정 시간 간격마다 waiting queue의 데이터를 하나씩 읽어 count만큼 entry queue로 옮기는 작업을 진행한다.

그러나 구현상 모든 이벤트의 모든 waiting queue의 모든 메시지를 읽어야 하므로, 메시지가 충분히 많다면, 이 작업은 오래 걸리고, 일정 간격 내에 
실행되지 못할 가능성이 높다.

현재 코드는 1초 간격으로 이 스케쥴링을 진행하고 있지만, 다시 말하자면 1초 이내에 처리가 불가능한 메시지량이 들어온다면 문제가 될 수 있다.

기존 스케쥴러가 끝나기 전에 새로운 스케쥴러가 생성되고, 이렇게 스케쥴러가 쌓이게 되면 스레드를 계속 소모해 스레드가 고갈될 것이다.

## 개선 방법
### 1. 스케쥴러의 성능 개선
기존 코드는 `redisTemplate.keys("WAITING_QUEUE:*")`를 사옹해 모든 이벤트의 대기열을 읽는다. 당연하게도 성능에 악영항을 준다.

대신 **읽어야 할 키들을 따로 보관해** 조회 성능을 개선할 수 있다.

### 2. scheduler의 fixedDelay 옵션
**일정한 주기** 이내에 실행을 포기한다면, 이 옵션이 해결책이 된다.

`fixedDelay`는 스케쥴러의 작업이 끝난 이후로부터 특정 기간 이후에 실행하게 하는 옵션이다. 이 옵션을 사용하면 여러 스케쥴러가 쌓이는 것을 막을
수 있다.

### 3. 비동기 처리

그러나 `fixedDelay`는 요구사항에 맞지 않는 해결방법이었고, 일정 주기로 클라이언트에게 응답이 가도록 하는 것이 중요하다고 생각했다.

그래서 이를 해결하기 위해 다음과 같은 방법을 사용했다.
1. 스케쥴러는 일정 주기로 worker에게 작업을 지시한다. 이때 모든 event의 waiting queue 키 값을 얻어 worker에게 보낸다.
2. worker는 비동기로 기존 스케쥴러가 하던 작업을 처리한다


* worker를 멀티스레딩으로 처리
`WAITING_QUEUE:{event-id}` 리스트를 스레드 개수만큼 쪼개거나, 일정 숫자로 쪼개서 각각의 승격을 스레드가 담당하도록 하는 것이다. 
  * Work-Stealing 모델 도입:
    1. 스케줄러: 1초마다 실행되어, 처리해야 할 모든 eventId 목록을 가져온 뒤, 이 목록을 Redis의 임시 LIST (예: PROMOTION_TASK_QUEUE)에 RPUSH 합니다.
    2. 워커 스레드: 각 스레드는 루프를 돌며 LPOP 명령어로 PROMOTION_TASK_QUEUE에서 자신이 처리할 eventId를 하나씩만 가져가서 처리합니다.


* 단일 스레드 비동기로 처리
`WAITING_QUEUE:{event-id}`를 모두 순회하면서 승격한다.



### 3-1. 비동기 처리의 문제점
이제 스케쥴링이 쌓이는 문제만 해결하면 된다.

#### 스레드 풀 설정
ThreadPoolTaskExecutor는 작업 요청이 들어왔을 때 무작정 새 스레드를 만들지 않습니다. 다음과 같은 명확한 순서에 따라 동작합니다.

1. corePoolSize 확인: 현재 일하고 있는 스레드 수가 corePoolSize보다 적으면, 새 스레드를 만들어 작업을 맡깁니다.
2. queueCapacity 확인: 만약 일하고 있는 스레드 수가 corePoolSize와 같다면, 새 스레드를 만들지 않고 들어온 작업을 큐(Queue)에 쌓습니다.
3. maxPoolSize 확인: 만약 큐마저 꽉 차면(queueCapacity 초과), 그때서야 maxPoolSize에 도달할 때까지 새 스레드를 추가로 만듭니다.
4. 거부(Reject): maxPoolSize까지 스레드가 꽉 찼고, 큐도 꽉 찼다면, 더 이상 작업을 받지 않고 에러(RejectedExecutionException)를 발생시킵니다.

corePoolSize -> queueCapacity -> maxPoolSize -> reject

* 이제 이 사이즈들을 어떻게 설정할 것인가?
* reject시에 어떻게 대응할 것인가?

##### 스레드 풀 설정값
승격 작업은 CPU를 많이 사용하기보다 외부 API 호출 등 IO 작업이 많다. 그러므로 그 시간동안 CPU는 다른 스레드를 실행할 수 있으므로,
코어 수보다 많은 스레드를 두는 것이 좋다.
* corePoolSize : CPU 코어 수 * 2
* maxPoolSize : corePoolSize와 동일

#### reject시 대응법
reject된 상황은 스케쥴링이 지속되면서 모든 스레드와 큐가 찼을 경우인데,
이 경우 백프레셔 전략을 생각해봐야 한다.

**백프레셔** : 소비자가 생산자의 속도를 따라가지 못할 때, 소비측의 부하를 생산자에게 전달해 생산 속도를 조절하는 기법.

생산자는 스케쥴러, 소비자는 워커 스레드이다. 즉, 워커 스레드의 임계점이 도달했을 시에, 스케쥴링이 중단되거나 느려져야 한다.( 최악의 경우 상정 )

최적의 백프레셔 전략: `CallerRunsPolicy`

`ThreadPoolTaskExecutor`의 `RejectedExecutionHandler`(거부 정책) 중 하나인 `CallerRunsPolicy`는 이 백프레셔를 구현하는 가장 간단하고 효과적인 방법입니다.

**CallerRunsPolicy의 동작 원리**
1. 정의: "새로운 작업을 스레드 풀에 제출했으나, 풀이 꽉 차서 거부당했을 때, 작업을 제출한 스레드(Caller)가 직접 그 작업을 실행하는 정책"입니다.
2. 우리 시스템에서의 적용:
   * Caller(호출자): `@Scheduled` 어노테이션에 의해 1초마다 작업을 생성하는 스케줄러 스레드입니다.
   * 동작 시나리오:
     1. 워커 스레드 풀이 가득 차고, 내부 큐까지 꽉 찹니다.
     2. 스케줄러 스레드가 새로운 작업(프로모션 로직)을 워커 스레드 풀에 제출합니다.
     3. 스레드 풀은 "더 이상 못 받겠다"며 작업을 거부합니다.
     4. `CallerRunsPolicy`가 발동되어, 거부된 작업을 스케줄러 스레드 자신이 직접 실행하기 시작합니다.
     5. 백프레셔 발생: 스케줄러 스레드는 프로모션 작업(I/O가 포함된 긴 작업)을 처리하느라 바빠집니다. 그 결과, 다음 `@Scheduled` 주기가 돌아와도 새로운 작업을 생성할 수 없게 됩니다.
     6. 결과: 생산자인 스케줄러의 작업 생성 속도가 소비자(워커 스레드)의 처리 속도에 맞춰 자연스럽게 느려집니다. 시스템은 다운되지 않고, 처리할 수 있는 만큼만 작업을 받게 됩니다.


